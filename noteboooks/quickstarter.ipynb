{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34782688-5c2e-4579-8c6a-d7600097a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fiona\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "from joblib import delayed, Parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bc1e6a-92c6-428d-849d-5cdb815996cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/d3y010/projects/atiim/data'\n",
    "\n",
    "gage_data_file = os.path.join(data_dir, 'tabular', 'water_level.csv')\n",
    "dem_file = os.path.join(data_dir, 'raster', 'run_1_all.sdat')\n",
    "basin_shp = os.path.join(data_dir, 'shp', 'basin_1.shp')\n",
    "gage_shp = os.path.join(data_dir, 'shp', 'gage_location_1.shp')\n",
    "\n",
    "output_dir = '/Users/d3y010/projects/atiim/test'\n",
    "\n",
    "run_name = 'test_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2d3d5-158a-4ec7-9b41-96fc1733d7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb786aef-21e5-4c06-a5a1-ffc0ef61b437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0641e4-d7cb-40e0-acc7-92a193364d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gage_data(gage_data_file):\n",
    "\n",
    "    df = pd.read_csv(gage_data_file)\n",
    "\n",
    "    # convert date and time strings to a pandas datetime type\n",
    "    df['date_time'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'], infer_datetime_format=True)\n",
    "\n",
    "    # sort df by date_time\n",
    "    df.sort_values(by=['date_time'], inplace=True)\n",
    "\n",
    "    min_wtr_elev = df['WL_ELEV_M'].min()\n",
    "    max_wtr_elev = df['WL_ELEV_M'].max()\n",
    "    wtr_elev_list = df['WL_ELEV_M'].tolist()\n",
    "    day_part, hour_interval = 1, 1\n",
    "    d_freq = df['WL_ELEV_M'].value_counts().to_dict()\n",
    "    \n",
    "    return min_wtr_elev, max_wtr_elev\n",
    "\n",
    "\n",
    "\n",
    "def create_basin_dem(basin_shp, dem_file, output_directory, run_name):\n",
    "    \"\"\"Mask the input DEM using a basin geometry representative of the contributing area.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # dissolve target basin geometries\n",
    "    basin_geom = gpd.read_file(basin_shp).dissolve().geometry.values[0]\n",
    "    \n",
    "    with rasterio.open(dem_file) as src:\n",
    "        \n",
    "        # apply basin geometry as a mask\n",
    "        out_image, out_transform = rasterio.mask.mask(src, basin_geom, crop=True)\n",
    "        \n",
    "        # update the raster metadata with newly cropped extent\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "        # write outputs\n",
    "        output_file = os.path.join(output_directory, f\"dem_masked_{run_name}.tif\")\n",
    "        with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "            \n",
    "        return output_file\n",
    "\n",
    "\n",
    "def process_slice(arr, upper_elev, transform, output_directory, target_crs):\n",
    "    \"\"\"Create a water level polygon shapefile containing a single feature that represents\n",
    "    the grid cells of an input DEM that are less than or equal to an upper elevation level.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # create every value greater than or equal to the upper elevation to 1, others to 0\n",
    "    arx = np.where(arr <= upper_elev, 1, 0).astype(np.int16)\n",
    "\n",
    "    # build each feature based on the extracted grid cells from the array\n",
    "    results = list(\n",
    "        {'properties': {'raster_val': val}, 'geometry': shp}\n",
    "        for index, (shp, val)  in enumerate(\n",
    "            shapes(arx, mask=None, transform=transform))\n",
    "    )\n",
    "\n",
    "    # list of geometries\n",
    "    geoms = list(results)\n",
    "\n",
    "    # build geopandas dataframe from geometries\n",
    "    gdf = gpd.GeoDataFrame.from_features(geoms, crs=target_crs)\n",
    "\n",
    "    # only keep the ones\n",
    "    gdf = gdf.loc[gdf['raster_val'] == 1]\n",
    "\n",
    "    # dissolve into a single polygon\n",
    "    gdf = gdf.dissolve('raster_val')\n",
    "\n",
    "    # write to file\n",
    "    out_file = os.path.join(output_directory, f'wl_{int(upper_elev)*10}.shp')\n",
    "    gdf.to_file(out_file)\n",
    "\n",
    "\n",
    "def generate_water_polygons(dem_file, \n",
    "                            basin_shp, \n",
    "                            gage_data_file, \n",
    "                            output_directory, \n",
    "                            run_name, \n",
    "                            elevation_interval=0.1):\n",
    "\n",
    "    # process gage data file\n",
    "    min_gage_elev, max_gage_elev = process_gage_data(gage_data_file)\n",
    "    \n",
    "    with rasterio.Env():\n",
    "        \n",
    "        # clip the input DEM to a target basin contributing area\n",
    "        masked_dem_file = create_basin_dem(basin_shp, dem_file, output_directory, run_name)\n",
    "\n",
    "        with rasterio.open(masked_dem_file) as src:\n",
    "\n",
    "            # read the raster band into a number array\n",
    "            arr = src.read(1)\n",
    "\n",
    "            # convert the raster nodata value to numpy nan\n",
    "            arr[arr == src.nodata] = np.nan\n",
    "\n",
    "            raster_min = np.nanmin(arr)\n",
    "            raster_max = np.nanmax(arr)\n",
    "            \n",
    "            # use the minimum bounding elevation e.g., the max of min available\n",
    "            elev_min = max([min_gage_elev, raster_min])\n",
    "            \n",
    "            # use the maximum bounding elevation e.g., the min of max available\n",
    "            elev_max = min([max_gage_elev, raster_max])\n",
    "            \n",
    "            # construct elevation upper bounds to process for each slice\n",
    "            elev_slices = np.arange(elev_min, elev_max, elevation_interval)\n",
    "            \n",
    "            # replace the last slice upper bound with the max elevation\n",
    "            elev_slices[-1] = elev_max\n",
    "\n",
    "            # process all elevation slices in parallel\n",
    "            Parallel(n_jobs=-1)(\n",
    "                delayed(process_slice)(arr, i, src.transform, output_directory, src.crs) \n",
    "                for i in elev_slices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7980a37b-8640-40b2-8a63-faaa877d44ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverIOError",
     "evalue": ".shp file is unreadable, or corrupt.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"fiona/ogrext.pyx\", line 1133, in fiona.ogrext.WritingSession.start\n  File \"fiona/_err.pyx\", line 291, in fiona._err.exc_wrap_pointer\nfiona._err.CPLE_AppDefinedError: .shp file is unreadable, or corrupt.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"<ipython-input-3-a1f83812befd>\", line 80, in process_slice\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/geopandas/geodataframe.py\", line 1086, in to_file\n    _to_file(self, filename, driver, schema, index, **kwargs)\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/geopandas/io/file.py\", line 327, in _to_file\n    with fiona.open(\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/fiona/env.py\", line 408, in wrapper\n    return f(*args, **kwargs)\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/fiona/__init__.py\", line 272, in open\n    c = Collection(path, mode, crs=crs, driver=driver, schema=this_schema,\n  File \"/Users/d3y010/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/fiona/collection.py\", line 165, in __init__\n    self.session.start(self, **kwargs)\n  File \"fiona/ogrext.pyx\", line 1141, in fiona.ogrext.WritingSession.start\nfiona.errors.DriverIOError: .shp file is unreadable, or corrupt.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDriverIOError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a1f83812befd>\u001b[0m in \u001b[0;36mgenerate_water_polygons\u001b[0;34m(dem_file, basin_shp, gage_data_file, output_directory, run_name, elevation_interval)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# process all elevation slices in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             Parallel(n_jobs=-1)(\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 for i in elev_slices)\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/py3.9.4_ml/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDriverIOError\u001b[0m: .shp file is unreadable, or corrupt."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "generate_water_polygons(dem_file, \n",
    "                        basin_shp, \n",
    "                        gage_data_file, \n",
    "                        output_dir, \n",
    "                        run_name, \n",
    "                        elevation_interval=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f7990-2262-44df-82f5-b0677aba6900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.4_ml",
   "language": "python",
   "name": "py3.9.4_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
